{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4457779-576e-4dd3-acda-a595bdc02bf6",
   "metadata": {},
   "source": [
    "# Process GESTALT barcodes from serially sampled sperm data \n",
    "##### Authors: \n",
    "###### Step A: Andy Sposato\n",
    "###### Step B: Andy Sposato\n",
    "###### Step C: Andy Sposato\n",
    "###### Step D: Andy Sposato\n",
    "###### Step E: Kimberly Truong & Andy Sposato\n",
    "######\n",
    "### A) Throw out whole files that have low total reads and write passed-samples-info.csv.\n",
    "##### Files that pass this step are given the extension: .passReadCounts. \n",
    "##### The passed-samples-info.csv is generated using only the .passReadCounts files. This csv will be important for step E when making the barcode matrix. \n",
    "### B) Filter barcodes by reads and proportion cutoffs. \n",
    "##### Barcodes that pass this step are added to files given the extension: .filteredReadCounts.  \n",
    "### C) Examine questionable barcodes and identify contaminant barcodes. \n",
    "##### To examine barcodes for each fish, a dictionary of barcodes was created for each fish. \n",
    "##### Fish dictionaries are written to files and stored in the \"fish_dictionaries\" folder which is at the same level as SpermAnalysis_Muller1. \n",
    "##### The list of questionable and good barcodes were written to files in the \"fish_dictionaries\" folder. \n",
    "### D) Remove contaminant barcodes from their read files. \n",
    "##### Barcodes that pass this step are added to files given the extension: .filteredQualityReadCounts.\n",
    "### E) Make barcode matrix. \n",
    "##### A composite barcode matrix file containing barcode information for all fish in the dataset is written to the experiments folder and used for generating Muller plots.\n",
    "##### Barcode matrix files for each individual fish are also written to the experiments folder.\n",
    "## Warnings: \n",
    "##### Make sure this python notebook file is stored at the same level as \"SpermAnalysis_Muller1\".\n",
    "##### This pipeline will break if you change your naming system for sample replicates or mess with the data structure Kimberly established. See github.com/Gagnon-lab/Sperm-Analysis for Kimberly's pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ae2dd6f-95bd-44e5-bfc5-2d24108d8d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os \n",
    "import re\n",
    "import operator\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from natsort import natsorted \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62559dff-3575-445b-af92-84cc41166de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_subfolder = \"./SpermAnalysis_Muller1/experiments/\" + datetime.datetime.today().strftime('%m.%d.%Y') + \"_\" + datetime.datetime.today().strftime('%I.%M_%p') + \"/\"\n",
    "# if the experiments_subfolder doesn't already exist, create it\n",
    "if not os.path.exists(experiments_subfolder): \n",
    "    os.mkdir(experiments_subfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "176dce32-312f-4288-ac9d-9ca0c2d1d713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./SpermAnalysis_Muller1/experiments/12.16.2024_10.14_AM/\n"
     ]
    }
   ],
   "source": [
    "print(experiments_subfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c41d60-1eb0-4aab-811e-cc6c405afdfc",
   "metadata": {},
   "source": [
    "## A) Throw out whole files that have low total reads and write passed-samples-info.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb6ebb9-db05-4703-9d02-7d1113cdff16",
   "metadata": {},
   "source": [
    "Currently, Kimberly's code relies on the user writing a samples-info.csv from scratch. We want to filter samples that are totally garbage (all barcodes have small numbers of reads). Then write a samples-info.csv based on the .allReadCounts files that remain after that step. We'll have to rewrite .allReadCounts we want to keep with a \"pass\" key in the name so that we can direct next steps to read just those files. Next steps include removing barcodes with low read numbers and proportions and removing contaminant barcodes from their samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba41f968-6863-4a6f-9eb7-5164629182d3",
   "metadata": {},
   "source": [
    "### Write .passedReadCounts files\n",
    "###### These are .allReadCounts files that have at least 1000 total reads across all barcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a110ebe-9f36-47ec-bb29-eb0fe15a75c0",
   "metadata": {},
   "source": [
    "#### Find all the .allReadCounts file paths in your data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73239a50-7f7d-43a6-892b-d96a155afb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/conno/Documents/sperm/process_sperm_barcodes\n"
     ]
    }
   ],
   "source": [
    "# where are we in the directory?\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba173365-ad73-48b6-bcbb-b1bcc5ebbf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example .allReadCounts filepath in your directory: ./SpermAnalysis_Muller1/data/viz-Output/fish1_s1_rep1/fish1_s1_rep1.allReadCounts\n"
     ]
    }
   ],
   "source": [
    "# get list of file paths leading to .allReadCounts files\n",
    "filepaths = []\n",
    "for dirpath, dirnames, filenames in os.walk(\".\"):\n",
    "   for filename in filenames:\n",
    "      if filename.endswith(\".allReadCounts\"):\n",
    "          filepath = os.path.join(dirpath, filename)\n",
    "          filepaths.append(filepath)\n",
    "\n",
    "filepaths = natsorted(filepaths)\n",
    "print(\"An example .allReadCounts filepath in your directory: \" + str(filepaths[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc04d027-a378-477d-b341-1188c660db16",
   "metadata": {},
   "source": [
    "#### Determine how many total reads are in each .allReadCounts file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c6fa59e-0c10-4ccd-ab7a-1d021da9594b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing...\n",
      "'path/to/.allReadCounts file': # reads in that .allReadCounts file:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how many reads are in each .allReadCounts file? \n",
    "print(\"Printing...\\n'path/to/.allReadCounts file': # reads in that .allReadCounts file:\\n\")\n",
    "for read_file in filepaths: \n",
    "    file = open(read_file, \"r\")\n",
    "    file.readline()\n",
    "    read_count_sum = 0\n",
    "    for lines in file.readlines(): \n",
    "        line = lines.split(\"\\t\")\n",
    "        barcode = line[0]\n",
    "        rank = line[1]\n",
    "        reads = int(line[2])\n",
    "        proportion = line[3]\n",
    "        read_count_sum += reads\n",
    "    # print(read_file + ': ' + str(read_count_sum))\n",
    "    file.close()      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673bdf0d-babc-4fde-9e25-599b3664d54d",
   "metadata": {},
   "source": [
    "#### Write the files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef98f74-bffa-431a-87a7-0a1aae57942a",
   "metadata": {},
   "source": [
    "##### In this next cell, we're making a list of files we'll keep for analysis. Andy and Jenna arbitrarily picked 1000 to explore this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05796877-5af2-4942-9760-98a29765abaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign an output directory, passed files should be in the same subfolder where allReadCounts files are\n",
    "output_dir = \"./SpermAnalysis_Muller1/data/viz-Output/\"\n",
    "\n",
    "# make an empty list that will hold the filepaths for allReadCount files we want to keep for analysis\n",
    "keep_read_files = []\n",
    "# for every path to an allReadCounts file\n",
    "for read_file in filepaths: \n",
    "    # grab info from the filepath and store as variables to use later\n",
    "    sample_id = read_file.split(\"/\") # split file path by '/'\n",
    "    sample_id = str(sample_id[-2]) # sample_id = full name of the sample (i.e. fishctrl3_s5_rep3)\n",
    "    fish = sample_id.split(\"_\")[0][4:] # fish is the fish identity (i.e. fish5)   \n",
    "    # now count reads in file \n",
    "    # open file for reading\n",
    "    file = open(read_file, \"r\") \n",
    "    # read the header\n",
    "    file.readline() \n",
    "    # set sum of read counts to zero before we start counting\n",
    "    read_count_sum = 0  \n",
    "    # store contents of read file line as a list called lines\n",
    "    lines = file.readlines() \n",
    "    # for each line in lines\n",
    "    for line in lines: \n",
    "        line = line.split(\"\\t\") # split file path by tab character\n",
    "        barcode = line[0] # barcode is first element\n",
    "        rank = line[1] # rank is second element\n",
    "        reads = int(line[2]) # make third element (reads) an integer\n",
    "        proportion = line[3] # proportion is third element\n",
    "        read_count_sum += reads # add the reads from that line to our read counter: read_count_sum\n",
    "    # if read_count_sum is bigger than 1000 - change this number later based on histogram data\n",
    "    total_read_cutoff = 999\n",
    "    if read_count_sum > total_read_cutoff: \n",
    "        # add the file path to the keep_read_files list\n",
    "        keep_read_files.append(read_file)\n",
    "    # close the file\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd65739-19c3-445b-8180-6ce66dab2d74",
   "metadata": {},
   "source": [
    "##### In this next cell, printing the list of files we're going to keep. This list can be checked with the results of the cell where we printed total reads in a file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa96d63a-7071-44ec-95ac-a8145cd601f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print file paths we're keeping\n",
    "# for filepath in keep_read_files: \n",
    "#     print(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf381b87-ed19-433c-a734-b2bfa2df2b9d",
   "metadata": {},
   "source": [
    "##### Looks right. In this next cell, we're writing the keep files (a copy of .allReadCounts that pass total read filter - 1000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80cfd24a-4040-4324-853a-73b2d6415f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for read_file in keep_read_files:\n",
    "    # grab info and store as variables \n",
    "    sample_id = read_file.split(\"/\")\n",
    "    sample_id = str(sample_id[-2])\n",
    "    fish = sample_id.split(\"_\")[0][4:]\n",
    "    # we're giving the copied files an extension name .passReadCounts so we can search for them later\n",
    "    keep_file = open(output_dir+'/'+sample_id+'/' + sample_id + '.passReadCounts', 'w')\n",
    "    file = open(read_file, \"r\")\n",
    "    for line in file.readlines(): \n",
    "        keep_file.write(line)\n",
    "    file.close()\n",
    "    keep_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7486a2-8c07-4967-84be-0c2741ca4bf5",
   "metadata": {},
   "source": [
    "Excellent. Now we can see that, for example, fish1_s9_rep1 and rep3 have .passReadCounts files, but not fish1_s9_rep2 (as expected). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d13e7d-26c4-4c95-9bdd-8a5bbb2f0436",
   "metadata": {},
   "source": [
    "### Now we automatically write the samples-info.csv file from .passReadCounts files\n",
    "###### This file is used later when we write the barcode matrix file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b089767-ab4d-4824-b35e-be182f32cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jenna started sampling fish when they were 4 months old\n",
    "start_age = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dac52c16-cdb9-45b5-bc88-c528f7f5b088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/conno/Documents/sperm/process_sperm_barcodes\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229bbcb0-39cf-42ad-bf34-b429f8c977ae",
   "metadata": {},
   "source": [
    "#### Find all the .passReadCounts file paths in your data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "232f60f4-efd6-45f2-b342-828390430dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example .passReadCounts filepath in your directory:\n",
      "./SpermAnalysis_Muller1/data/viz-Output/fish1_s1_rep1/fish1_s1_rep1.passReadCounts\n"
     ]
    }
   ],
   "source": [
    "filepaths = []\n",
    "for dirpath, dirnames, filenames in os.walk(\".\"):\n",
    "   for filename in filenames:\n",
    "      if filename.endswith(\".passReadCounts\"):\n",
    "          filepath = os.path.join(dirpath, filename)\n",
    "          filepaths.append(filepath)\n",
    "\n",
    "filepaths = natsorted(filepaths)\n",
    "print(\"An example .passReadCounts filepath in your directory:\\n\" + str(filepaths[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193c178f-430f-4d7a-a6b7-495e05374a6b",
   "metadata": {},
   "source": [
    "#### Gather the information from the file name that will go into the contents of sample-info.csv and write it\n",
    "###### We write the output file as \"passed-samples-info.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2df5722b-a9c6-4cbb-a3d3-202ed6bd3c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from each file path, we want the sample_id (filename), fish id, age (sample+4), replicate, edited vs control\n",
    "file = open(\"SpermAnalysis_Muller1/data/passed-samples-info.csv\", \"w\")\n",
    "file.write(\"sample_id,fish,age,replicate,condition\\n\")\n",
    "for read_file in filepaths: \n",
    "    # grab info and store as variables \n",
    "    sample_id = read_file.split(\"/\")\n",
    "    sample_id = str(sample_id[-2])\n",
    "    fish = sample_id.split(\"_\")[0][4:]\n",
    "    sample = sample_id.split(\"_\")[1][1:]\n",
    "    replicate = sample_id.split(\"_\")[2][3:]\n",
    "    age = str(int(sample) + start_age)\n",
    "    if 'ctrl' in sample_id: \n",
    "        condition = 'control'\n",
    "    else: \n",
    "        condition = 'edited'\n",
    "    file.write(sample_id+','+fish+','+age+','+replicate+','+condition+'\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f554f8-07f8-4acb-b50e-0d865573a2f3",
   "metadata": {},
   "source": [
    "### Step A summary report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75dfda26-9840-4dae-a40d-c6fdf4a607aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "allReadCounts_files = 0\n",
    "passReadCounts_files = 0\n",
    "passed_samples = []\n",
    "failed_samples = []\n",
    "\n",
    "# count files, add passing to passed_samples\n",
    "for dirpath, dirnames, filenames in os.walk(\".\"):\n",
    "   for filename in filenames:\n",
    "      if filename.endswith(\".allReadCounts\"):\n",
    "          allReadCounts_files += 1 \n",
    "      elif filename.endswith(\".passReadCounts\"):\n",
    "          passReadCounts_files += 1\n",
    "          sample_id = filename.split(\".\") # split file path by '.'\n",
    "          sample_id = str(sample_id[0]) # sample_id = full name of the sample (i.e. fishctrl3_s5_rep3)\n",
    "          passed_samples.append(sample_id)\n",
    "        \n",
    "# get list of filepaths leading to .allReadCounts files  \n",
    "filepaths = []\n",
    "for dirpath, dirnames, filenames in os.walk(\".\"):\n",
    "   for filename in filenames:\n",
    "      if filename.endswith(\".allReadCounts\"):\n",
    "          filepath = os.path.join(dirpath, filename)\n",
    "          filepaths.append(filepath)\n",
    "\n",
    "# get list of failed samples\n",
    "for filename in filepaths:\n",
    "    sample_id = filename.split(\"/\") # split file path by '/'\n",
    "    sample_id = str(sample_id[-2]) # sample_id = full name of the sample (i.e. fishctrl3_s5_rep3)\n",
    "    if sample_id not in passed_samples: \n",
    "        failed_samples.append(sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71c7a61d-8319-4b2b-9134-a18fc862111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = open(experiments_subfolder + \"stepA_summary.txt\", \"w\")\n",
    "summary.write(\"Summary of step A: Throw out whole files that have low total reads and write passed-samples-info.csv.\\n\\n\")\n",
    "summary.write(\"Your data contains \" + str(allReadCounts_files) + ' .allReadCounts files, or ' + str(allReadCounts_files) + ' samples including replicates.\\n\\n')\n",
    "summary.write(\"If a file contained at least\" + str(total_read_cutoff) + \" total reads across all barcodes, then it has passed this filter step.\\n\") \n",
    "summary.write(\"\\n\")\n",
    "if allReadCounts_files == passReadCounts_files: \n",
    "    summary.write(\"All of your files passed this step.\\n\")\n",
    "elif allReadCounts_files < passReadCounts_files:\n",
    "    summary.write(\"Something has gone wrong. You have more .passReadsCounts files than .allReadCounts files which should be impossible. Please check your data folders for duplicate read files.\")\n",
    "elif allReadCounts_files > passReadCounts_files:\n",
    "    summary.write(str(allReadCounts_files-passReadCounts_files) + \" files failed this step:\\n\")\n",
    "    for read_file in filepaths: \n",
    "        #print(read_file)\n",
    "        filename = read_file.split(\"/\")\n",
    "        sample_id = filename[-2]\n",
    "        #print(filename)\n",
    "        if sample_id in failed_samples: \n",
    "            file = open(read_file, \"r\")\n",
    "            file.readline()\n",
    "            read_count_sum = 0\n",
    "            for lines in file.readlines(): \n",
    "                line = lines.split(\"\\t\")\n",
    "                barcode = line[0]\n",
    "                rank = line[1]\n",
    "                reads = int(line[2])\n",
    "                proportion = line[3]\n",
    "                read_count_sum += reads\n",
    "            summary.write(sample_id+ ' failed with only ' + str(read_count_sum) + ' total reads. \\n')\n",
    "        file.close()\n",
    "summary.write(\"\\n\")\n",
    "summary.write(str(passReadCounts_files) + \" files passed the filter.\\n\\n\")\n",
    "summary.write(\"The contents of those passing files were copied to a new file with the extension name '.passReadCounts' \\nin the same subfolder.\\n\\n\")\n",
    "summary.write(\"The passed-samples-info.csv was also written and saved to the folder called data.\\nIt contains only samples that pass this step.\\n\")\n",
    "summary.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb0a81a-8d4e-49b8-bf14-a8e9f8f90d24",
   "metadata": {},
   "source": [
    "## B) Filter barcodes by reads and proportion cutoffs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b8958c-73d4-4288-92e2-99d848e1051e",
   "metadata": {},
   "source": [
    "### Gather .passReadCounts files\n",
    "###### These are .allReadCounts files that have at least 1000 total reads across all barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8c88685-10ce-463c-98e1-b96c5bb11326",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = []\n",
    "for dirpath, dirnames, filenames in os.walk(\".\"):\n",
    "   for filename in filenames:\n",
    "      if filename.endswith(\".passReadCounts\"):\n",
    "          filepath = os.path.join(dirpath, filename)\n",
    "          filepaths.append(filepath)\n",
    "\n",
    "filepaths = natsorted(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a74da3e-42c7-4f28-bceb-fd80c180431a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./SpermAnalysis_Muller1/data/viz-Output/fish1_s1_rep1/fish1_s1_rep1.passReadCounts\n",
      "12D+34_12D+60_NONE_NONE_3D+143_84D+169_84D+169_84D+169_84D+169_NONE\t0\t57559\t0.750511780736182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# just making sure the file contents are what we expect \n",
    "print(filepaths[0])\n",
    "file = open(filepaths[0], 'r')\n",
    "file.readline()\n",
    "print(file.readline())\n",
    "file.close()\n",
    "\n",
    "# should look something like this: \n",
    "#./SpermAnalysis_Muller1/data/viz-Output/fish1_s3_rep1/fish1_s3_rep1.passReadCounts\n",
    "#1D+38_28D+41_NONE_NONE_NONE_NONE_NONE_NONE_NONE_NONE\t0\t2434\t0.5138273168672155"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf2847b-effb-42a7-8456-bccf68c69da4",
   "metadata": {},
   "source": [
    "### Write .filteredReadCounts files\n",
    "###### These files will contain barcodes that have a minimum of 10 reads and a minimum proportion of 0.005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fad34406-e83d-4f5a-a7ca-cc9b497b54e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_output_dir = \"./SpermAnalysis_Muller1/data/viz-Output\"\n",
    "# for every read file\n",
    "for read_file in filepaths: \n",
    "    # grab sample and rep info and store as variables \"fish_id_name\" and \"samp_rep\"\n",
    "    fish_id = read_file.split(\"/\")\n",
    "    fish_id = str(fish_id[-2])\n",
    "    # open file for reading\n",
    "    inputfile = open(read_file, \"r\")\n",
    "    outputfile = open(filtered_output_dir+'/'+fish_id+'/' + fish_id + '.filteredReadCounts', 'w')\n",
    "    outputfile.write('event' + '\\t' + 'array' + '\\t' + 'count' + '\\t' + 'proportion' + '\\n')\n",
    "    # read the first line so we can ignore the headers in the loop\n",
    "    inputfile.readline()\n",
    "    # for each line containing a barcode in the allReadCounts file\n",
    "    for lines in inputfile.readlines(): \n",
    "        # identify each element\n",
    "        line = lines.split('\\t')\n",
    "        barcode = line[0]\n",
    "        rank = line[1]\n",
    "        reads = line[2]\n",
    "        proportion = line[3]\n",
    "        prop = proportion[0:-1]\n",
    "        # if the barcode is found at a proportion of at least .005 and has at least 10 reads\n",
    "        prop_cutoff = .005\n",
    "        reads_cutoff = 10\n",
    "        if float(prop) >= prop_cutoff and int(reads) >= reads_cutoff:\n",
    "            outputfile.write(lines)\n",
    "    outputfile.close()\n",
    "    inputfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68126dd-59e9-420f-a824-d30e253c4c0c",
   "metadata": {},
   "source": [
    "### Step B summary report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06b4bfa6-db02-4bea-aa4d-bf7c676321a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_samples = []\n",
    "# \n",
    "for dirpath, dirnames, filenames in os.walk(\".\"):\n",
    "   for filename in filenames:\n",
    "      if filename.endswith(\".filteredReadCounts\"):\n",
    "          sample_id = filename.split(\".\") # split file path by '.'\n",
    "          sample_id = str(sample_id[0]) # sample_id = full name of the sample (i.e. fishctrl3_s5_rep3)\n",
    "          filtered_samples.append(sample_id)\n",
    "filtered_samples_sorted = natsorted(filtered_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "217ed48d-b426-4f74-9be0-8fabc5f5fb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_string = './SpermAnalysis_Muller1/data/viz-Output/' \n",
    "for sample_id in filtered_samples_sorted: \n",
    "    with open(filepath_string + sample_id + '/' + sample_id +'.filteredReadCounts', 'r') as filtered_file: \n",
    "        with open(filepath_string + sample_id + '/' + sample_id +'.passReadCounts', 'r') as pass_file:\n",
    "            difference = set(pass_file).difference(filtered_file)\n",
    "    difference.discard(\"\\n\")\n",
    "    with open(filepath_string+sample_id+'/'+sample_id+'_'+'stepB_removed_barcodes.txt', 'w') as file_out: \n",
    "        file_out.write(\"event\" + '\\t' + \"array\" + '\\t' + \"count\" +'\\t' + \"proportion\" + '\\n')\n",
    "        for line in difference: \n",
    "            file_out.write(line)\n",
    "    filtered_file.close()\n",
    "    pass_file.close()\n",
    "    file_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddc58812-21ac-477c-8387-fa1d76976eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = open(experiments_subfolder + \"stepB_summary.txt\", 'w')\n",
    "summary.write(\"Summary of step B: Filter barcodes by reads and proportion cutoffs.\\n\\n\")\n",
    "summary.write(\"For each .passReadCounts file, if a barcode had fewer than \" + str(reads_cutoff) + \" reads or a proportion below \" + str(prop_cutoff) + \",\\nit was removed from the file.\\n\\n\")\n",
    "summary.write(\"Passing barcodes for each sample were written to a sample file with the extension: .filteredReadCounts\\n\\n\")\n",
    "summary.write(\"A list of barcodes that were removed was written to a sample file that ends with 'stepB_removed_barcodes.txt'\\nThis may be useful to verify that the changes from .passReadCounts to .filteredReadCounts were accurate.\\n\\n\")\n",
    "summary.write(\"Here is a recap of the filtering for each sample: \\n\\n\") \n",
    "summary.write(\"**************************************************************************************** \\n\\n\")\n",
    "\n",
    "filepath_string = './SpermAnalysis_Muller1/data/viz-Output/' \n",
    "\n",
    "for sample_id in filtered_samples_sorted: \n",
    "    pass_read_counts = 0\n",
    "    with open(filepath_string + sample_id + '/' + sample_id +'.passReadCounts', 'r') as pass_file:\n",
    "        pass_file.readline()\n",
    "        for lines in pass_file.readlines(): \n",
    "            line = lines.split(\"\\t\")\n",
    "            barcode = line[0]\n",
    "            rank = line[1]\n",
    "            reads = int(line[2])\n",
    "            proportion = line[3]\n",
    "            pass_read_counts += reads\n",
    "            pass_file.close()\n",
    "    filtered_read_counts = 0\n",
    "    with open(filepath_string + sample_id + '/' + sample_id +'.filteredReadCounts', 'r') as filtered_file: \n",
    "        filtered_file.readline()\n",
    "        for lines in filtered_file.readlines(): \n",
    "            line = lines.split(\"\\t\")\n",
    "            barcode = line[0]\n",
    "            rank = line[1]\n",
    "            reads = int(line[2])\n",
    "            proportion = line[3]\n",
    "            filtered_read_counts += reads\n",
    "            filtered_file.close()\n",
    "    reads_removed = pass_read_counts-filtered_read_counts\n",
    "    summary.write(sample_id + \" had \" + str(pass_read_counts) + \" reads in the .passReadCounts file. Filtering removed \" + str(reads_removed) + ' reads.\\n')\n",
    "    summary.write(\"There are now \" + str(filtered_read_counts) + \" reads in the \" + sample_id + \".filteredReadCounts file.\\n\\n\")\n",
    "    \n",
    "    filtered_count = 0\n",
    "    with open(filepath_string + sample_id + '/' + sample_id +'.filteredReadCounts', 'r') as filtered_file:\n",
    "        filtered_file.readline()\n",
    "        for line in filtered_file.readlines(): \n",
    "            filtered_count += 1\n",
    "    filtered_file.close()\n",
    "    pass_count = 0\n",
    "    with open(filepath_string + sample_id + '/' + sample_id +'.passReadCounts', 'r') as pass_file:\n",
    "        pass_file.readline()\n",
    "        for line in pass_file.readlines(): \n",
    "            pass_count += 1\n",
    "    pass_file.close()\n",
    "    barcodes_removed = pass_count-filtered_count\n",
    "    summary.write(sample_id + \" had \" + str(pass_count) + \" barcodes in the .passReadCounts file. Filtering removed \" + str(barcodes_removed) + ' barcodes.\\n')\n",
    "    if filtered_count == 1: \n",
    "        summary.write(\"There is now \" + str(filtered_count) + \" barcode in the \" + sample_id + \".filteredReadCounts file.\\n\\n\")\n",
    "    else:     \n",
    "        summary.write(\"There are now \" + str(filtered_count) + \" barcodes in the \" + sample_id + \".filteredReadCounts file.\\n\\n\")\n",
    "    summary.write(\"**************************************************************************************** \\n\\n\")\n",
    "summary.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb071330-bffc-4d68-a3e2-32a71997390d",
   "metadata": {},
   "source": [
    "## C) Examine questionable barcodes and identify contaminant barcodes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c619ff-930a-4ca6-be6d-7284e231c3f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Questionable barcodes are barcodes that show up in multiple animals. They are likely contamination. We want to confidently remove them from samples where they do not belong. Before we can remove them from the appropriate files, we need to examine each according to the number of reads that support them in every fish. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c4c195-2ced-417f-86f9-5957c97f9e3d",
   "metadata": {},
   "source": [
    "### Make fish dictionaries\n",
    "###### These will store all barcodes and their sample occurence on a fish by fish basis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "caffa50b-e901-4239-9801-a2b265344269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepaths = []\n",
    "# for dirpath, dirnames, filenames in os.walk(\".\"):\n",
    "#    for filename in filenames:\n",
    "#       if filename.endswith(\".filteredReadCounts\"):\n",
    "#           filepath = os.path.join(dirpath, filename)\n",
    "#           filepaths.append(filepath)\n",
    "# filepaths = natsorted(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e57042ed-17c0-4c79-956d-e80a0f20fce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # just making sure the file contents are what we expect \n",
    "# print(filepaths[0])\n",
    "# file = open(filepaths[0], 'r')\n",
    "# file.readline()\n",
    "# print(file.readline())\n",
    "# file.close()\n",
    "\n",
    "# # should look something like this: \n",
    "# #./SpermAnalysis_Muller1/data/viz-Output/fish1_s3_rep1/fish1_s3_rep1.filteredReadCounts\n",
    "# #1D+38_28D+41_NONE_NONE_NONE_NONE_NONE_NONE_NONE_NONE\t0\t2434\t0.5138273168672155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3f63592-506f-42ce-a4d2-248a521b6232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make a dictionary to hold all fish dictionaries \n",
    "# # make each fish start with an empty dictionary\n",
    "# fishes = {}\n",
    "# for path in filepaths: \n",
    "#     path = path.split(\"/\")\n",
    "#     filename = path[-2]\n",
    "#     fish = filename.split(\"_\")\n",
    "#     fish_name = fish[0]\n",
    "#     if fish_name not in fishes:\n",
    "#         fishes[fish_name] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2260fead-8de0-474e-a3e8-7279822fe3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # so we should see a key for each fish in your data with a starting value of an empty dictionary\n",
    "# # like: ('fish1', {})\n",
    "# for fish in fishes.items(): \n",
    "#     print(fish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38482abd-4df2-49cb-8d42-ccd384a423d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for every read file\n",
    "# for read_file in filepaths: \n",
    "#     # grab sample and rep info and store as variables \"fish_id_name\" and \"samp_rep\"\n",
    "#     fish_id = read_file.split(\"/\")\n",
    "#     fish_id = fish_id[-2]\n",
    "#     fish_id = fish_id.split(\"_\")\n",
    "#     fish_id_name = fish_id[0]\n",
    "#     sample_name = fish_id[1]\n",
    "#     sample = sample_name[1:]\n",
    "#     replicate = fish_id[2]\n",
    "#     rep_num = replicate[-1]\n",
    "#     samp_rep = sample+\".\"+rep_num\n",
    "#     # if the fish id name matches a dictionary name in fishes\n",
    "#     if fish_id_name in fishes:\n",
    "#         # then open file for reading \n",
    "#         file = open(read_file, \"r\")\n",
    "#         # read the first line so we can ignore the headers in the loop\n",
    "#         file.readline()\n",
    "#         # for each line containing a barcode in the allReadCounts file\n",
    "#         for line in file.readlines(): \n",
    "#             # identify each element\n",
    "#             line = line.split('\\t')\n",
    "#             barcode = line[0]\n",
    "#             rank = line[1]\n",
    "#             reads = line[2]\n",
    "#             proportion = line[3]\n",
    "#             prop = proportion[0:-1]\n",
    "#             # if the barcode is not found as a key in the fish's dictionary\n",
    "#             if barcode not in fishes[fish_id_name].keys(): \n",
    "#                 # then add it as a new key and store the sample replicate information as the first item in a list for that barcode's value\n",
    "#                 fishes[fish_id_name][barcode] = [samp_rep+':'+prop+':'+reads]\n",
    "#             # else if the barcode already exists as a key in the fish's directory\n",
    "#             else:\n",
    "#                 # then just add this sample replicate information to the list \n",
    "#                 if samp_rep not in fishes[fish_id_name][barcode]: \n",
    "#                     fishes[fish_id_name][barcode].append(samp_rep+':'+prop+':'+reads)\n",
    "#         file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343b14a3-8f74-4b80-9572-2552d43af880",
   "metadata": {},
   "source": [
    "### Write fish dictionaries to files \n",
    "###### This is so they can be read easily in Excel or a Text program like Notepad++ or BBEdit.\n",
    "###### This is also helpful so they don't need to be recreated several times downstream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c93f3fdd-acd8-474c-bd75-802e81836a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if the fish_dictionaries folder doesn't already exist, create it\n",
    "# if not os.path.exists('./fish_dictionaries/'): \n",
    "#     os.mkdir(\"./fish_dictionaries/\")\n",
    "# output_dir = \"./fish_dictionaries/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "206d72e9-748a-4aa4-ac0f-53f119e89835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write a file for each fish dictionary \n",
    "# # for every fish in the fishes dictionary\n",
    "# for fish in fishes.keys(): \n",
    "#     # create an output tsv file\n",
    "#     with open(output_dir+fish+\"_dictionary.tsv\", 'w') as f: \n",
    "#         # write a header on the first line\n",
    "#         f.write(fish +'\\t' + 'barcode' + '\\t' + 'sample'+ '\\t' + 'proportion'+ '\\t' + 'read count'+'\\n')\n",
    "#         # for each line, write the barcode (i) and the sample reps it shows up in within that fish (j)\n",
    "#         for i,j in fishes[fish].items():\n",
    "#             f.write('\\t' + i)\n",
    "#             f.write('\\n')\n",
    "#             for sample_detection in j:\n",
    "#                 samp_detect = sample_detection.split(\":\")\n",
    "#                 sample = samp_detect[0]\n",
    "#                 prop = samp_detect[1]\n",
    "#                 reads = samp_detect[2]\n",
    "#                 f.write('\\t' + '\\t' + sample + '\\t' + prop + '\\t' + reads + '\\n')\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "615592bf-d260-417a-88d6-17f89f96ab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write all dictionaries to one file called \"fishes_dictionaries\"\n",
    "# with open(output_dir+\"fishes_dictionaries.tsv\", \"w\") as f: \n",
    "#     # write a header on the first line\n",
    "#     f.write('fish' +'\\t' + 'barcode' + '\\t' + 'sample'+ '\\t' + 'proportion'+ '\\t' + 'read count'+'\\n')\n",
    "#     for fish in fishes.keys():\n",
    "#         # for each line, write the barcode (i) and the sample reps it shows up in within that fish (j)\n",
    "#         f.write(fish)\n",
    "#         f.write('\\n')\n",
    "#         for i,j in fishes[fish].items():\n",
    "#             f.write('\\t' + i)\n",
    "#             f.write('\\n')\n",
    "#             for sample_detection in j:\n",
    "#                 samp_detect = sample_detection.split(\":\")\n",
    "#                 sample = samp_detect[0]\n",
    "#                 prop = samp_detect[1]\n",
    "#                 reads = samp_detect[2]\n",
    "#                 f.write('\\t' + '\\t' + sample + '\\t' + prop + '\\t' + reads + '\\n')\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e44665-1927-4b11-8d01-545200ff6b9e",
   "metadata": {},
   "source": [
    "### Find questionable barcodes\n",
    "###### These are barcodes that show up in multiple fish. \n",
    "###### A barcode will not be tagged questionable if it shows up in multiple samples or replicates of a single fish. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "daf50247-42cc-43ab-83cc-2237997540eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepaths = []\n",
    "# for dirpath, dirnames, filenames in os.walk(\".\"):\n",
    "#    for filename in filenames:\n",
    "#       if filename.endswith(\"dictionary.tsv\"):\n",
    "#           filepath = os.path.join(dirpath, filename)\n",
    "#           filepaths.append(filepath)\n",
    "# filepaths = natsorted(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2d7ca93-e110-4327-97f1-f8e926114291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make a list to hold all fish names\n",
    "# fish_list = []\n",
    "# for path in filepaths: \n",
    "#     path = path.split(\"/\")\n",
    "#     # file name should be the last element when separated by /\n",
    "#     filename = path[-1]\n",
    "#     fish = filename.split(\"_\")\n",
    "#     # fish name should be the first element when filename is separated by _\n",
    "#     fish_name = fish[0]\n",
    "#     # add all fish names to fish list\n",
    "#     if fish_name not in fish_list:\n",
    "#         fish_list.append(fish_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e204ef81-17ae-43ba-adbb-5894759f7940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the unedited barcode string as a variable\n",
    "unedited = \"NONE_NONE_NONE_NONE_NONE_NONE_NONE_NONE_NONE_NONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "522c995b-3a21-41cd-983e-50f8258887b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_barcodes = []\n",
    "# good_barcodes = []\n",
    "# bad_barcodes = []\n",
    "# questionable_barcodes = []\n",
    "\n",
    "# # for all fish dictionary tsv files\n",
    "# for read_file in filepaths: \n",
    "#     # open the file \n",
    "#     file = open(read_file, 'r')\n",
    "#     # read the first line to grab the fish name\n",
    "#     fish = file.readline().split(\"\\t\")[0]\n",
    "#     # for the barcode and sample replicate occurrence in each line\n",
    "#     for line in file.readlines(): \n",
    "#         line = line.split(\"\\t\")\n",
    "#         # grab the barcode \n",
    "#         barcode = line[1]\n",
    "#         barcode = barcode[0:-1]\n",
    "#         # if the barcode is not the unedited barcode, compare it to barcodes from other fish\n",
    "#         if barcode != unedited: \n",
    "#             # if the barcode is not in all barcodes, \n",
    "#             if barcode not in all_barcodes: \n",
    "#                 # add it to all barcodes \n",
    "#                 all_barcodes.append(barcode)\n",
    "#             # but \n",
    "#             else:\n",
    "#                 # if it is already in all barcodes\n",
    "#                 if barcode in all_barcodes:\n",
    "#                     # and not in bad barcodes yet\n",
    "#                     if barcode not in bad_barcodes: \n",
    "#                         # add it to bad barcodes list\n",
    "#                         bad_barcodes.append(barcode)\n",
    "#                         # this should prevent bad barcodes from being added twice or more to the bad barcodes list\n",
    "# file.close()\n",
    "\n",
    "# # for every barcode in all barcodes\n",
    "# for barcode in all_barcodes: \n",
    "#     # if it's not in bad barcodes\n",
    "#     if barcode not in bad_barcodes: \n",
    "#         # it is a good barcode\n",
    "#         good_barcodes.append(barcode)\n",
    "\n",
    "# for barcode in bad_barcodes: \n",
    "#     if barcode != '': \n",
    "#         questionable_barcodes.append(barcode)\n",
    "\n",
    "# good_barcodes.append(unedited)\n",
    "# all_barcodes.append(unedited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04cb6d02-97c6-4a2d-8002-5b811b7a4946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"These barcodes are suspicious because they either occur 'naturally' in multiple animals or they are a contaminant barcode in some animals:\")\n",
    "# for barcode in questionable_barcodes:\n",
    "#     print(barcode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1204b1-c3be-4d1e-a491-c604a21bdb63",
   "metadata": {},
   "source": [
    "It is recommended that you write your list of questionable barcodes to a text file so that if you need to pause analysis you can simply reload the list later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ec81562-188b-4661-9be3-30c88be6d0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write questionable barcodes to a file\n",
    "# output = open(output_dir+'questionable_barcodes_list.txt', 'w')\n",
    "# for barcode in questionable_barcodes: \n",
    "#     output.write(barcode)\n",
    "#     output.write(\"\\n\")\n",
    "# output.close()\n",
    "# # write good barcodes to a file\n",
    "# output = open(output_dir+'good_barcodes_list.txt', 'w')\n",
    "# for barcode in good_barcodes: \n",
    "#     output.write(barcode)\n",
    "#     output.write(\"\\n\")\n",
    "# output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98cfb30a-b1df-40be-972a-a0b102e2cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load in the questionable barcodes list, we will examine them\n",
    "# barcodes_to_examine = []\n",
    "# output_dir = \"./fish_dictionaries/\"\n",
    "# file = open(output_dir+'questionable_barcodes_list.txt', \"r\")\n",
    "# print(\"contents of 'questionable_barcodes_list.txt': \") \n",
    "# for line in file:\n",
    "#     line = line.split(\"\\n\")\n",
    "#     barcode = line[0]\n",
    "#     #print(barcode)\n",
    "#     barcodes_to_examine.append(barcode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f43a9f-13b0-426c-8865-570f842ae1ac",
   "metadata": {},
   "source": [
    "### Examine questionable barcodes for contamination status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdea0552-88ff-46fb-a1d7-5943e7003319",
   "metadata": {},
   "source": [
    "##### Gather read information for each questionable barcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c446eef-53cb-424d-839a-2fed6f9b8791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make a dictionary to hold all barcode dictionaries \n",
    "# # make each barcode start with an empty dictionary\n",
    "# questionable_barcodes = {}\n",
    "# for barcode in barcodes_to_examine: \n",
    "#         questionable_barcodes[barcode] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83591348-b3e9-4fc3-a7ac-6f574fb7556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = []\n",
    "for dirpath, dirnames, filenames in os.walk(\"./SpermAnalysis_Muller1\"):\n",
    "   for filename in filenames:\n",
    "      if filename.endswith(\".filteredReadCounts\"):\n",
    "          filepath = os.path.join(dirpath, filename)\n",
    "          filepaths.append(filepath)\n",
    "\n",
    "filepaths = natsorted(filepaths)\n",
    "# print(filepaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4454533d-3f44-4f10-9447-22204facb844",
   "metadata": {},
   "source": [
    "Connor's additions start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "588a122d-dded-4296-a2dc-765d55cdd7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fd stands for \"filtered data\"\n",
    "fd = pd.DataFrame(columns = [\"barcode\", \"fish\", \"sample\", \"replicate\", \"reads\"])\n",
    "\n",
    "# count reads associated with each questionable barcode across all fish \n",
    "for read_file in filepaths:\n",
    "    # read_file has the format:\n",
    "    # \"./SpermAnalysis_Muller1/data/viz-Output/fish<X>_s<Y>_rep<Z>/fish<X>_s<Y>_rep<Z>.filteredReadCounts\"\n",
    "\n",
    "    # Split this string into an array using \"/\" as delimiters\n",
    "    folder_name = read_file.split(\"/\")\n",
    "\n",
    "    # fish_id[-2] has the format \"fish<X>_s<Y>_rep<Z>\"\n",
    "    fishX, sY, repZ = folder_name[-2].split(\"_\")\n",
    "\n",
    "    # Save the fish number (e.g. \"fish12\" gets saved as \"12\").\n",
    "    # Similar for sample and replicate.\n",
    "    fish_id = fishX\n",
    "    sample = sY[1:]\n",
    "    replicate = repZ[3:]\n",
    "    \n",
    "    # Open the .filteredReadCounts file.\n",
    "    file = open(read_file, \"r\")\n",
    "    \n",
    "    # Read the first line so we can ignore the headers in the loop\n",
    "    file.readline()\n",
    "    for line in file.readlines():\n",
    "        # Identify each element and add a row to the DataFrame\n",
    "        line = line.split('\\t')\n",
    "        barcode = line[0]\n",
    "        rank = line[1]\n",
    "        reads = int(line[2])\n",
    "        fd.loc[len(fd.index)] = [barcode, fish_id, sample, replicate, reads]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3d76142-e67d-475e-acb5-e7020fde6bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_questionable(data):\n",
    "    barcodes = data[data[\"barcode\"] != unedited].barcode.unique()\n",
    "\n",
    "    data[\"questionable\"] = False\n",
    "    data[\"contamination_rank\"] = pd.NA\n",
    "    data[\"ratio\"] = np.inf\n",
    "\n",
    "    for bc in barcodes:\n",
    "        one_bc = data[data.barcode == bc]\n",
    "        \n",
    "        if len(one_bc.fish.unique()) > 1:\n",
    "            # Barcode is not unique, it is questionable\n",
    "            data.loc[(data.barcode == bc), \"questionable\"] = True\n",
    "        \n",
    "            # For each fish, rank the level of contamination (e.g. the fish with the most\n",
    "            # total reads of the barcode gets rank 0, then the fish with the second gets\n",
    "            # most reads gets rank 1, and so on.\n",
    "            aggregate = one_bc.groupby(by = 'fish', as_index = False, observed = True) \\\n",
    "                              .aggregate({'reads': 'sum'})\n",
    "\n",
    "            aggregate.sort_values('reads', ascending = False, inplace = True, ignore_index = True)\n",
    "\n",
    "            winner_reads = aggregate.reads.iloc[0]\n",
    "            total_reads = aggregate.reads.sum()\n",
    "        \n",
    "            ratio = winner_reads / (total_reads - winner_reads)\n",
    "            data.loc[(data.barcode == bc), \"ratio\"] = ratio\n",
    "            \n",
    "            for i, fish in enumerate(aggregate.fish):\n",
    "                data.loc[(data.barcode == bc) & (data.fish == fish), \"contamination_rank\"] = i\n",
    "\n",
    "    data[\"contamination_rank\"] = data[\"contamination_rank\"].astype('Int64', errors = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bec03da1-4a9e-4c35-9bb8-f5a398fa30f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>barcode</th>\n",
       "      <th>fish</th>\n",
       "      <th>sample</th>\n",
       "      <th>replicate</th>\n",
       "      <th>reads</th>\n",
       "      <th>questionable</th>\n",
       "      <th>contamination_rank</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12D+34_12D+60_NONE_NONE_3D+143_84D+169_84D+169...</td>\n",
       "      <td>fish1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57559</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>887.366548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1D+38_28D+41_NONE_NONE_NONE_NONE_54D+199_54D+1...</td>\n",
       "      <td>fish1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10646</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>36.670098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7D+36_12D+60_NONE_1I+119+A&amp;5D+121_19D+130_4S+1...</td>\n",
       "      <td>fish1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1958</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>190.235012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1D+38_28D+41_NONE_18D+113_NONE_NONE_54D+199_54...</td>\n",
       "      <td>fish1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1345</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1D+38_28D+41_NONE_NONE_NONE_NONE_NONE_NONE_NON...</td>\n",
       "      <td>fish1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>792</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>237.812121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             barcode   fish  sample  \\\n",
       "0  12D+34_12D+60_NONE_NONE_3D+143_84D+169_84D+169...  fish1       1   \n",
       "1  1D+38_28D+41_NONE_NONE_NONE_NONE_54D+199_54D+1...  fish1       1   \n",
       "2  7D+36_12D+60_NONE_1I+119+A&5D+121_19D+130_4S+1...  fish1       1   \n",
       "3  1D+38_28D+41_NONE_18D+113_NONE_NONE_54D+199_54...  fish1       1   \n",
       "4  1D+38_28D+41_NONE_NONE_NONE_NONE_NONE_NONE_NON...  fish1       1   \n",
       "\n",
       "   replicate  reads  questionable  contamination_rank       ratio  \n",
       "0          1  57559          True                   0  887.366548  \n",
       "1          1  10646          True                   0   36.670098  \n",
       "2          1   1958          True                   0  190.235012  \n",
       "3          1   1345         False                <NA>         inf  \n",
       "4          1    792          True                   0  237.812121  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd[\"fish\"] = fd[\"fish\"].astype('category')\n",
    "fd[\"sample\"] = pd.to_numeric(fd[\"sample\"])\n",
    "fd[\"reads\"] = pd.to_numeric(fd[\"reads\"])\n",
    "fd[\"replicate\"] = pd.to_numeric(fd[\"replicate\"])\n",
    "identify_questionable(fd)\n",
    "fd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af2ae578-1484-4a55-a868-276dd560b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for barcode in questionable_barcodes.keys(): \n",
    "#     for read_file in filepaths: \n",
    "#         # grab sample and rep info and store as variables \"fish_id_name\" and \"samp_rep\"\n",
    "#         fish_id = read_file.split(\"/\")\n",
    "#         fish_id = fish_id[-2]\n",
    "#         fish_id = fish_id.split(\"_\")\n",
    "#         fish_id_name = fish_id[0]\n",
    "#         if fish_id_name not in barcode: \n",
    "#             questionable_barcodes[barcode][fish_id_name] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "926245d2-cfe3-4ed7-ba0e-23eda7b2b203",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd.loc[:, \"complete_triple_rep_filter\"] = False\n",
    "fd.loc[:, \"fish_triple_rep_filter\"] = False\n",
    "fd.loc[:, \"fish_one_sample_filter\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f77b4d0-190f-4c22-ad2a-4a4dc69f0175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of questionable barcodes: 292\n"
     ]
    }
   ],
   "source": [
    "qd = fd.loc[fd.questionable, :]\n",
    "barcodes_to_examine = qd.barcode.unique()\n",
    "print(f\"number of questionable barcodes: {len(barcodes_to_examine)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24c007bf-98d8-4146-807d-afed1fcedf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rep_count = np.zeros_like(barcodes_to_examine) \n",
    "for bc in barcodes_to_examine:\n",
    "    single_bc = qd[qd.barcode == bc].copy()\n",
    "    single_bc[\"rep_count\"] = 1\n",
    "    grouped = single_bc.groupby(['fish', 'sample'], observed = True, as_index = False).aggregate({'rep_count': 'sum'})\n",
    "    if grouped.rep_count.max() < 3:\n",
    "        fd.loc[qd[qd.barcode == bc].index, \"complete_triple_rep_filter\"] = True\n",
    "\n",
    "    for fish in single_bc.fish.unique():\n",
    "        grouped = single_bc[single_bc.fish == fish].groupby(['sample'], as_index = False).aggregate({'rep_count': 'sum'})\n",
    "        if grouped.rep_count.max() < 3:\n",
    "            # never appears in 3 reps, throw out\n",
    "            fd.loc[qd[(qd.barcode == bc) & (qd.fish == fish)].index, \"fish_triple_rep_filter\"] = True\n",
    "        if len(grouped) == 1:\n",
    "            # only appears in one sample, throw out\n",
    "            fd.loc[qd[(qd.barcode == bc) & (qd.fish == fish)].index, \"fish_one_sample_filter\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0cbe0d47-58ad-4888-9f4a-a8887436d6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>barcode</th>\n",
       "      <th>fish</th>\n",
       "      <th>sample</th>\n",
       "      <th>replicate</th>\n",
       "      <th>reads</th>\n",
       "      <th>questionable</th>\n",
       "      <th>contamination_rank</th>\n",
       "      <th>ratio</th>\n",
       "      <th>complete_triple_rep_filter</th>\n",
       "      <th>fish_triple_rep_filter</th>\n",
       "      <th>fish_one_sample_filter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12D+34_12D+60_NONE_NONE_3D+143_84D+169_84D+169...</td>\n",
       "      <td>fish1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57559</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>887.366548</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1D+38_28D+41_NONE_NONE_NONE_NONE_54D+199_54D+1...</td>\n",
       "      <td>fish1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10646</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>36.670098</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7D+36_12D+60_NONE_1I+119+A&amp;5D+121_19D+130_4S+1...</td>\n",
       "      <td>fish1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1958</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>190.235012</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1D+38_28D+41_NONE_18D+113_NONE_NONE_54D+199_54...</td>\n",
       "      <td>fish1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1345</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>inf</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1D+38_28D+41_NONE_NONE_NONE_NONE_NONE_NONE_NON...</td>\n",
       "      <td>fish1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>792</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>237.812121</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             barcode   fish  sample  \\\n",
       "0  12D+34_12D+60_NONE_NONE_3D+143_84D+169_84D+169...  fish1       1   \n",
       "1  1D+38_28D+41_NONE_NONE_NONE_NONE_54D+199_54D+1...  fish1       1   \n",
       "2  7D+36_12D+60_NONE_1I+119+A&5D+121_19D+130_4S+1...  fish1       1   \n",
       "3  1D+38_28D+41_NONE_18D+113_NONE_NONE_54D+199_54...  fish1       1   \n",
       "4  1D+38_28D+41_NONE_NONE_NONE_NONE_NONE_NONE_NON...  fish1       1   \n",
       "\n",
       "   replicate  reads  questionable  contamination_rank       ratio  \\\n",
       "0          1  57559          True                   0  887.366548   \n",
       "1          1  10646          True                   0   36.670098   \n",
       "2          1   1958          True                   0  190.235012   \n",
       "3          1   1345         False                <NA>         inf   \n",
       "4          1    792          True                   0  237.812121   \n",
       "\n",
       "   complete_triple_rep_filter  fish_triple_rep_filter  fish_one_sample_filter  \n",
       "0                       False                   False                   False  \n",
       "1                       False                   False                   False  \n",
       "2                       False                   False                   False  \n",
       "3                       False                   False                   False  \n",
       "4                       False                   False                   False  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a93337a7-1550-457b-820b-e6bd6416af87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.02979461e+00, 1.29670010e+00, 1.64220705e+00, 1.96580955e+00,\n",
       "       2.47822892e+00, 2.64412190e+00, 3.36326455e+00, 3.57065013e+00,\n",
       "       4.30050615e+00, 4.50896475e+00, 5.37056633e+00, 5.79285030e+00,\n",
       "       1.13930197e+01, 1.21429930e+01, 7.01885157e+01, 8.73703320e+01,\n",
       "       1.79752683e+02, 2.08826435e+02, 3.01349931e+02, 3.56025896e+02,\n",
       "       6.00022297e+02, 2.10591133e+03,            inf])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cd stands for \"classified data\"\n",
    "cd = fd[(~fd.complete_triple_rep_filter) & (~fd.fish_triple_rep_filter) & (~fd.fish_one_sample_filter)].copy()\n",
    "identify_questionable(cd)\n",
    "print(len(cd[cd.questionable].barcode.unique()))\n",
    "ratios = cd.ratio.unique()\n",
    "ratios.sort()\n",
    "ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e15b025-5b5e-44d6-845a-4338ee29eaa2",
   "metadata": {},
   "source": [
    "We have 22 remaining barcodes to handle. For now, I do the following:\n",
    "* Barcodes with a ratio above 50 are automatically given to the \"winner\"\n",
    "* Barcodes with a ratio below 50 are dropped (this can be improved on but I will get to that later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f83c814-607e-41d6-b980-a269d0daa58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd2 = cd.drop(cd[cd.ratio < 50].index)\n",
    "cd2 = cd2.drop(cd2[(cd2.ratio != np.inf) & (cd2.contamination_rank > 0)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5bb9bd7c-4ce4-476b-8d8b-8bd5b7a845dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>barcode</th>\n",
       "      <th>fish</th>\n",
       "      <th>sample</th>\n",
       "      <th>replicate</th>\n",
       "      <th>reads</th>\n",
       "      <th>questionable</th>\n",
       "      <th>contamination_rank</th>\n",
       "      <th>ratio</th>\n",
       "      <th>complete_triple_rep_filter</th>\n",
       "      <th>fish_triple_rep_filter</th>\n",
       "      <th>fish_one_sample_filter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12D+34_12D+60_NONE_NONE_3D+143_84D+169_84D+169...</td>\n",
       "      <td>fish1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57559</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>inf</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1D+38_28D+41_NONE_NONE_NONE_NONE_54D+199_54D+1...</td>\n",
       "      <td>fish1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10646</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2105.91133</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7D+36_12D+60_NONE_1I+119+A&amp;5D+121_19D+130_4S+1...</td>\n",
       "      <td>fish1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1958</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>inf</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1D+38_28D+41_NONE_18D+113_NONE_NONE_54D+199_54...</td>\n",
       "      <td>fish1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1345</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>inf</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1D+38_28D+41_NONE_NONE_NONE_NONE_NONE_NONE_NON...</td>\n",
       "      <td>fish1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>792</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>inf</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             barcode   fish  sample  \\\n",
       "0  12D+34_12D+60_NONE_NONE_3D+143_84D+169_84D+169...  fish1       1   \n",
       "1  1D+38_28D+41_NONE_NONE_NONE_NONE_54D+199_54D+1...  fish1       1   \n",
       "2  7D+36_12D+60_NONE_1I+119+A&5D+121_19D+130_4S+1...  fish1       1   \n",
       "3  1D+38_28D+41_NONE_18D+113_NONE_NONE_54D+199_54...  fish1       1   \n",
       "4  1D+38_28D+41_NONE_NONE_NONE_NONE_NONE_NONE_NON...  fish1       1   \n",
       "\n",
       "   replicate  reads  questionable  contamination_rank       ratio  \\\n",
       "0          1  57559         False                <NA>         inf   \n",
       "1          1  10646          True                   0  2105.91133   \n",
       "2          1   1958         False                <NA>         inf   \n",
       "3          1   1345         False                <NA>         inf   \n",
       "4          1    792         False                <NA>         inf   \n",
       "\n",
       "   complete_triple_rep_filter  fish_triple_rep_filter  fish_one_sample_filter  \n",
       "0                       False                   False                   False  \n",
       "1                       False                   False                   False  \n",
       "2                       False                   False                   False  \n",
       "3                       False                   False                   False  \n",
       "4                       False                   False                   False  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c599984-e28f-4354-badf-acedf4388f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionable_barcodes_summary = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8714e8aa-2d2a-4d72-9d8b-05c0fe132da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bc in barcodes_to_examine:\n",
    "    fish_w_barcode = cd2[cd2.barcode == bc].fish.unique()\n",
    "    if len(fish_w_barcode) == 0:\n",
    "        questionable_barcodes_summary[bc] = \"contaminant\"\n",
    "    elif len(fish_w_barcode) == 1:\n",
    "        questionable_barcodes_summary[bc] = fish_w_barcode[0]\n",
    "    else:\n",
    "        raise Exception(\"Still some contamination\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e621ce-c8cf-4db2-bd8a-6f9bf11d231b",
   "metadata": {},
   "source": [
    "##### **ESSENTIAL STEP:** Without generating a questionable_barcodes dictionary that contains the read counts, you cannot hope proceed to part D. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da54918d-ac02-4614-b6e1-dfdd4ff8fbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # count reads associated with each questionable barcode across all fish and assign to barcode\n",
    "# for read_file in filepaths:\n",
    "#     # grab sample and rep info and store as variables \"fish_id_name\" and \"samp_rep\"\n",
    "#     fish_id = read_file.split(\"/\")\n",
    "#     fish_id = fish_id[-2]\n",
    "#     fish_id = fish_id.split(\"_\")\n",
    "#     fish_id_name = fish_id[0]\n",
    "#     # then open file for reading \n",
    "#     file = open(read_file, \"r\")\n",
    "#     # read the first line so we can ignore the headers in the loop\n",
    "#     file.readline()\n",
    "#     for line in file.readlines():\n",
    "#         # identify each element\n",
    "#         line = line.split('\\t')\n",
    "#         barcode = line[0]\n",
    "#         rank = line[1]\n",
    "#         reads = int(line[2])\n",
    "#         for questionable_barcode in questionable_barcodes.keys(): \n",
    "#             if questionable_barcode == barcode: \n",
    "#                 questionable_barcodes[questionable_barcode][fish_id_name] += reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "487b8684-a49d-44a6-b6fc-d12bf1f56922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read questionable_barcodes dictionary\n",
    "# for barcode in questionable_barcodes.keys():\n",
    "#     for dict in questionable_barcodes.values(): \n",
    "#         print(barcode)\n",
    "#         for key,value in dict.items():\n",
    "#             print(str(key) + \": \" + str(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5048078-cc17-4ff6-a6c9-1dfa23a43728",
   "metadata": {},
   "source": [
    "##### Calculate ratios of winners to all losers. \n",
    "###### You can skip this part and move on to Step 4 if you are not trying to explore the contamination data with a histogram and just want the list of questionable barcodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cbc00866-64f4-4d9d-a989-70aebbd4c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make a new dictionary to hold just the read counts\n",
    "# questionable_barcode_library = {}\n",
    "# for barcode in questionable_barcodes.keys(): \n",
    "#     questionable_barcode_library[barcode] = []\n",
    "# for questionable_barcode in questionable_barcodes.keys(): \n",
    "#     for barcode in questionable_barcode_library.keys(): \n",
    "#         if barcode == questionable_barcode: \n",
    "#             questionable_barcode_library[barcode] = list(questionable_barcodes[questionable_barcode].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c1b9b7b7-eafb-4a2b-9028-75daa2a80c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sort read count lists\n",
    "# for read_count_list in questionable_barcode_library.values(): \n",
    "#     read_count_list = read_count_list.sort(reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4ed6c3b0-cb4d-4a91-a6f5-867c7465bb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_v_losers_ratios = []\n",
    "# for read_count_list in questionable_barcode_library.values(): \n",
    "#     first_place = float(read_count_list[0])\n",
    "#     losers = sum(read_count_list[1:])\n",
    "#     ratio = first_place/losers\n",
    "#     first_v_losers_ratios.append(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ea186b-e116-4449-9f54-d12857f46145",
   "metadata": {},
   "source": [
    "###### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a409a033-21e9-48ad-920e-4473d75be1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot histogram of winner ratios\n",
    "# # need to play with the axes to determine best values for your data\n",
    "# data = first_v_losers_ratios\n",
    "# bins = 20\n",
    "# plt.xlim([-10, 700])\n",
    "# plt.ylim([0, 14])\n",
    "# plt.hist(data, bins=bins, alpha=0.5)\n",
    "# plt.title('Contamination summary')\n",
    "# plt.xlabel(\"1st place fish's read count / all losers' read count sum\")\n",
    "# plt.ylabel('count')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704dd417-8358-4a73-9d1d-91bb43321953",
   "metadata": {},
   "source": [
    "### Step C summary report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "53d527f9-dcbe-486d-b2a2-7db0dd46b49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = open(experiments_subfolder+\"stepC_summary.txt\", 'w')\n",
    "summary.write(\"Summary of step C: Examine questionable barcodes and identify contaminant barcodes.\\n\\n\")\n",
    "summary.write(\"A fish dictionary was created for each fish in your data and written to a file like fish1_dictionary.tsv \\n\\n\")\n",
    "summary.write(\"A dictionary holds every barcode found in any sample or replicate belonging to that animal.\\n\")\n",
    "summary.write(\"For each barcode in that dictionary, information about:\\n\\t1) the sample replicate it showed up in,\\n\\t2) the proportion of that sample replicate's barcode population\\n\\t3) the number of reads associated with that barcode within the sample replicate\\n\")\n",
    "summary.write(\"All dictionaries were also compiled into one file called fishes_dictionaries.tsv.\\n\\n\")\n",
    "summary.write(\"The fish dictionaries were used to compare barcode occurrence across fish.\\nQuestionable barcodes are barcodes that show up in multiple fish.\\nThis list was written to questionable_barcodes_list.txt.\\n\")\n",
    "summary.write(\"\\nThe rest of this step is exploring those questionable barcodes. The next set of filtered files\\nare generated in Step D.\\n\")\n",
    "summary.write(\"\\nHere is an example fish dictionary: \\n\\n\") \n",
    "\n",
    "dict_file = open(\"fish_dictionaries/fishctrl3_dictionary.tsv\", \"r\")\n",
    "for line in dict_file.readlines(): \n",
    "    summary.write(line)\n",
    "dict_file.close()\n",
    "\n",
    "summary.write(\"\\n\")\n",
    "summary.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed23a49-1702-471c-ac13-0ce2f172732e",
   "metadata": {},
   "source": [
    "## D) Remove contaminant barcodes from read files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ecf621-2087-41b1-8eaf-f2988bd8d828",
   "metadata": {},
   "source": [
    "The intent here is to remove barcodes that are contamination in just the fish where they don't belong. So for every questionable barcode, we want to categorize if it's a contaminant everywhere or has a source. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcdb012-cf19-4264-9035-563d5b4d7c1f",
   "metadata": {},
   "source": [
    "### Sort questionable_barcodes dictionary\n",
    "###### We want the fish with the highest number of reads to be listed last in the dictionary of each questionable barcode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d2a1a7a0-7be7-40ab-a64a-436524ff78b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sort the questionable_barcodes dictionary so that the fish are in ascending order according to reads\n",
    "# # save this as sorted_questionable_barcodes\n",
    "# sorted_questionable_barcodes = {}\n",
    "# for barcode, dictionary in questionable_barcodes.items(): \n",
    "#     sorted_dictionary_values = sorted(dictionary.items(), key=operator.itemgetter(1))\n",
    "#     sorted_dictionary = collections.OrderedDict(sorted_dictionary_values)\n",
    "#     sorted_questionable_barcodes[barcode] = (sorted_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cfd680-b55d-4899-a3ec-5dd78fa79a8e",
   "metadata": {},
   "source": [
    "### Associate each barcode with a contamination status\n",
    "##### To determine a source fish, it must contain 199x more reads than the sum of all other fish.\n",
    "###### Connor and Jenna are working on visualizing the read data for the whole data set. We'll alter this ratio cutoff later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "61d1b902-3ba2-4061-8893-e73f936fbf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this dictionary will convert the reads information from sorted_questionable_barcodes into a qualitative dictionary called questionable_barcodes_summary\n",
    "# # in questionable_barcodes_summary, a barcode key will have a value that is either 'contaminant' or the source fish that barcode came from\n",
    "# questionable_barcodes_summary = {}\n",
    "# for barcode,dictionary in sorted_questionable_barcodes.items(): \n",
    "#     dictionary = str(dictionary)[13:-3]\n",
    "#     dictionary_parts = dictionary.split(\"),\")\n",
    "#     total_reads = 0\n",
    "#     read_count_list = []\n",
    "#     samples = []\n",
    "#     for part in dictionary_parts:\n",
    "#         info = part.split(\", \")\n",
    "#         sample = info[0][1:]\n",
    "#         samples.append(sample)\n",
    "#         reads = int(info[1])\n",
    "#         read_count_list.append(reads)\n",
    "#         total_reads += int(info[1])\n",
    "#     winner = int(read_count_list[-1])\n",
    "#     losers_sum = total_reads-winner\n",
    "#     if winner == total_reads: \n",
    "#         ratio = 1\n",
    "#     else: \n",
    "#         ratio = winner/losers_sum\n",
    "#     # if the fish with the most reads has > 199x more reads than the rest of the fish, it is the source of that barcode\n",
    "#     if ratio > 199: \n",
    "#         source = samples[-1][2:-1]\n",
    "#         questionable_barcodes_summary[barcode] = source\n",
    "#     # if not, the barcode is questionable everywhere and we call it contaminant\n",
    "#     else: \n",
    "#         questionable_barcodes_summary[barcode] = 'contaminant'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd638c2-4538-4cbb-b280-21f633459a3c",
   "metadata": {},
   "source": [
    "### Remove contaminant barcodes from .filteredReadCount files\n",
    "##### This will rewrite all of our .filteredReadCounts files as .filteredQualityReadCounts\n",
    "###### Contaminant barcodes without a clear source are removed everywhere.\n",
    "###### Contaminant barcodes with a clear source are removed everywhere except files belonging to the source fish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d00d7482-5f5f-4b66-97de-48ae63473dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = []\n",
    "for dirpath, dirnames, filenames in os.walk(\".\"):\n",
    "   for filename in filenames:\n",
    "      if filename.endswith(\".filteredReadCounts\"):\n",
    "          filepath = os.path.join(dirpath, filename)\n",
    "          filepaths.append(filepath)\n",
    "\n",
    "filepaths = natsorted(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ee853528-b8ae-4896-a8b8-ebc229bd1602",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_output_dir = \"./SpermAnalysis_Muller1/data/viz-Output\"\n",
    "for read_file in filepaths: \n",
    "    # grab sample and rep info and store as variables \"fish_id_name\" and \"samp_rep\"\n",
    "    fish_id = read_file.split(\"/\")\n",
    "    fish_id = str(fish_id[-2])\n",
    "    fish = fish_id.split(\"_\")\n",
    "    fish = fish[0]\n",
    "    # open file for reading\n",
    "    inputfile = open(read_file, \"r\")\n",
    "    outputfile = open(filtered_output_dir+'/'+fish_id+'/' + fish_id + '.filteredQualityReadCounts', 'w')\n",
    "    outputfile.write('event' + '\\t' + 'array' + '\\t' + 'count' + '\\t' + 'proportion' + '\\n')\n",
    "    # read the first line so we can ignore headers\n",
    "    inputfile.readline()\n",
    "    for lines in inputfile.readlines(): \n",
    "    # identify each element\n",
    "        line = lines.split('\\t')\n",
    "        barcode = line[0]\n",
    "        rank = line[1]\n",
    "        reads = line[2]\n",
    "        proportion = line[3]\n",
    "        prop = proportion[0:-1]\n",
    "        # if the barcode is not questionable, then just copy the line exactly to the new file\n",
    "        if barcode not in questionable_barcodes_summary.keys(): \n",
    "            outputfile.write(lines) \n",
    "        else: \n",
    "            # but if it is questionable,\n",
    "            if barcode in questionable_barcodes_summary.keys(): \n",
    "                # copy to the new file only if the source fish exactly matches the fish name from this file\n",
    "                if questionable_barcodes_summary[barcode] == fish: \n",
    "                    outputfile.write(lines)\n",
    "    outputfile.close()\n",
    "    inputfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d66468-ade4-4f69-bb35-2fe06cb24258",
   "metadata": {},
   "source": [
    "The .filteredQualityReadCounts is written to the same subfolder where the original .allReadCounts file, .passReadCounts file and .filteredReadCounts file are. The .filteredQualityReadCounts should be used as the input in the make barcode matrix code. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f5d97b-a724-43ef-9d95-a2313bfa7cb0",
   "metadata": {},
   "source": [
    "### Step D summary report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c4fd060e-6a80-4502-b3a3-2135b5760695",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_quality_samples = []\n",
    "for dirpath, dirnames, filenames in os.walk(\".\"):\n",
    "   for filename in filenames:\n",
    "      if filename.endswith(\".filteredQualityReadCounts\"):\n",
    "          sample_id = filename.split(\".\") # split file path by '.'\n",
    "          sample_id = str(sample_id[0]) # sample_id = full name of the sample (i.e. fishctrl3_s5_rep3)\n",
    "          filtered_quality_samples.append(sample_id)\n",
    "filtered_quality_samples_sorted = natsorted(filtered_quality_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8396b529-9d98-4eb2-8bee-c9e33a2d084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = open(experiments_subfolder+\"stepD_summary.txt\", 'w')\n",
    "summary.write(\"Summary of step D: Remove contaminant barcodes from their read files.\\n\\n\")\n",
    "summary.write(\"The barcodes in questionable barcodes list were examined carefully for their presence across animals.\\n\")\n",
    "summary.write(\"If a clear source of that barcode could be found, the questionable barcode was assigned a source fish.\\n\")\n",
    "summary.write(\"If there was not a clear winner, the questionable barcode was considered contaminant everywhere.\\n\\n\")\n",
    "summary.write(\"For each questionable barcode, it was removed from the .filteredReadCounts files where it is considered contamination.\\n\")\n",
    "summary.write(\"The new read files are written with the extension: .filteredQualityReadCounts\\n\\n\")\n",
    "summary.write(\"\\nHere is a recap of the filtering for each sample: \\n\\n\")\n",
    "summary.write(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ \\n\\n\")\n",
    "\n",
    "filepath_string = './SpermAnalysis_Muller1/data/viz-Output/'\n",
    "\n",
    "for sample_id in filtered_quality_samples_sorted: \n",
    "    pass_read_counts = 0\n",
    "    with open(filepath_string + sample_id + '/' + sample_id +'.filteredReadCounts', 'r') as pass_file:\n",
    "        pass_file.readline()\n",
    "        for lines in pass_file.readlines(): \n",
    "            line = lines.split(\"\\t\")\n",
    "            barcode = line[0]\n",
    "            rank = line[1]\n",
    "            reads = int(line[2])\n",
    "            proportion = line[3]\n",
    "            pass_read_counts += reads\n",
    "            pass_file.close()\n",
    "    filtered_read_counts = 0\n",
    "    with open(filepath_string + sample_id + '/' + sample_id +'.filteredQualityReadCounts', 'r') as filtered_file: \n",
    "        filtered_file.readline()\n",
    "        for lines in filtered_file.readlines(): \n",
    "            line = lines.split(\"\\t\")\n",
    "            barcode = line[0]\n",
    "            rank = line[1]\n",
    "            reads = int(line[2])\n",
    "            proportion = line[3]\n",
    "            filtered_read_counts += reads\n",
    "            filtered_file.close()\n",
    "    reads_removed = pass_read_counts-filtered_read_counts\n",
    "    summary.write(sample_id + \" had \" + str(pass_read_counts) + \" reads in the .filteredReadCounts file. Filtering removed \" + str(reads_removed) + ' reads.\\n')\n",
    "    summary.write(\"There are now \" + str(filtered_read_counts) + \" reads in the \" + sample_id + \".filteredQualityReadCounts file.\\n\\n\")\n",
    "\n",
    "    filtered_count = 0\n",
    "    with open(filepath_string + sample_id + '/' + sample_id +'.filteredQualityReadCounts', 'r') as filtered_file:\n",
    "        filtered_file.readline()\n",
    "        for line in filtered_file.readlines(): \n",
    "            filtered_count += 1\n",
    "    filtered_file.close()\n",
    "    pass_count = 0\n",
    "    with open(filepath_string + sample_id + '/' + sample_id +'.filteredReadCounts', 'r') as pass_file:\n",
    "        pass_file.readline()\n",
    "        for line in pass_file.readlines(): \n",
    "            pass_count += 1\n",
    "    pass_file.close()\n",
    "    barcodes_removed = pass_count-filtered_count\n",
    "    if pass_count == 1: \n",
    "        if barcodes_removed == 0:\n",
    "            summary.write(sample_id + \" had \" + str(pass_count) + \" barcode in the .filteredReadCounts file. Filtering removed \" + str(barcodes_removed) + ' barcodes.\\n')\n",
    "        elif barcodes_removed == 1: \n",
    "            summary.write(sample_id + \" had \" + str(pass_count) + \" barcode in the .filteredReadCounts file. Filtering removed the barcode.\\n\")\n",
    "    elif pass_count > 1: \n",
    "        if barcodes_removed == 1: \n",
    "            summary.write(sample_id + \" had \" + str(pass_count) + \" barcodes in the .filteredReadCounts file. Filtering removed \" + str(barcodes_removed) + ' barcode.\\n')\n",
    "        else: \n",
    "            summary.write(sample_id + \" had \" + str(pass_count) + \" barcodes in the .filteredReadCounts file. Filtering removed \" + str(barcodes_removed) + ' barcodes.\\n')\n",
    "    if filtered_count == 1: \n",
    "        summary.write(\"There is \" + str(filtered_count) + \" barcode in the \" + sample_id + \".filteredQualityReadCounts file.\\n\\n\")\n",
    "    else:     \n",
    "        summary.write(\"There are \" + str(filtered_count) + \" barcodes in the \" + sample_id + \".filteredQualityReadCounts file.\\n\\n\")\n",
    "\n",
    "    \n",
    "    with open(filepath_string + sample_id + '/' + sample_id +'.filteredQualityReadCounts', 'r') as filtered_quality_file: \n",
    "        with open(filepath_string + sample_id + '/' + sample_id +'.filteredReadCounts', 'r') as filtered_file:\n",
    "            difference = set(filtered_file).difference(filtered_quality_file)\n",
    "    difference.discard(\"\\n\")\n",
    "    if len(difference) == 0: \n",
    "        summary.write(\"No barcodes were removed from \" + sample_id + '.filteredReadCounts. \\n')\n",
    "    elif len(difference) == 1:\n",
    "        summary.write(\"This barcode was removed from \" + sample_id + '.filteredReadCounts: \\n')\n",
    "        for line in difference: \n",
    "            barcode = line.split(\"\\t\")[0]\n",
    "            if barcode in  questionable_barcodes_summary.keys(): \n",
    "                if questionable_barcodes_summary[barcode] == 'contaminant': \n",
    "                    summary.write('\\t' + barcode + \": promiscuous barcode\\n\" )\n",
    "                else: \n",
    "                    summary.write('\\t' + barcode + \": contamination from \" + questionable_barcodes_summary[barcode] + \"\\n\") \n",
    "    else: \n",
    "        summary.write(\"These barcodes were removed from \" + sample_id + '.filteredReadCounts: \\n')\n",
    "        for line in difference: \n",
    "            barcode = line.split(\"\\t\")[0]\n",
    "            if barcode in  questionable_barcodes_summary.keys(): \n",
    "                if questionable_barcodes_summary[barcode] == 'contaminant': \n",
    "                    summary.write('\\t' + barcode + \": promiscuous barcode\\n\" )\n",
    "                else: \n",
    "                    summary.write('\\t' + barcode + \": contamination from \" + questionable_barcodes_summary[barcode] + \"\\n\")    \n",
    "    summary.write(\"\\n\")\n",
    "    summary.write(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ \\n\\n\")\n",
    "    filtered_quality_file.close()\n",
    "    filtered_file.close()\n",
    "summary.write(\"\\n\")\n",
    "summary.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec388d7-7518-4211-b115-a17c48309fe8",
   "metadata": {},
   "source": [
    "## E) Make barcode matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2adbd7-70a9-4d37-bde5-e025ed967bf2",
   "metadata": {},
   "source": [
    "The barcode matrix will be used as input when generating Muller plots in R. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "03682d38-6e2d-4d6a-8a4b-779d3bf3e4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/conno/Documents/sperm/process_sperm_barcodes\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d14b6f-755b-4bd3-8b57-b1b6c0c893dc",
   "metadata": {},
   "source": [
    "### Assemble the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8cc4522a-7b63-4283-9b80-815a217469ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     fish  age replicate condition\n",
      "sample_id                                         \n",
      "fish1_s1_rep1           1    5         1    edited\n",
      "fish1_s1_rep2           1    5         2    edited\n",
      "fish1_s1_rep3           1    5         3    edited\n",
      "fish1_s2_rep1           1    6         1    edited\n",
      "fish1_s2_rep2           1    6         2    edited\n",
      "...                   ...  ...       ...       ...\n",
      "fishwater_s7_rep1   water   11         1    edited\n",
      "fishwater_s9_rep1   water   13         1    edited\n",
      "fishwater_s10_rep2  water   14         2    edited\n",
      "fishwater_s12_rep5  water   16         5    edited\n",
      "fishwater_s13_rep7  water   17         7    edited\n",
      "\n",
      "[1015 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# load passed-sample-info.csv\n",
    "samples_df = pd.read_csv(\"./SpermAnalysis_Muller1/data/passed-samples-info.csv\", sep=\",\", index_col=0, dtype={'replicate':'category'})\n",
    "# Andy commented out the next line so this code will read your control samples. To look at edited fish only, uncomment the next line:\n",
    "#samples_df = samples_df[samples_df['condition']=='edited']\n",
    "print(samples_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4d47e60d-2793-4a71-8667-f90402fd28e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataframe should already be ordered, but go ahead and run this\n",
    "# reorder dataframe rows by fish then date \n",
    "samples_df.sort_values(by=['fish','age'], inplace=True)\n",
    "ind_sorted = samples_df.index\n",
    "# you can check by uncommenting the following lines\n",
    "#print(\"After reordering for clustering: \") \n",
    "#print(samples_df)\n",
    "#print(\"This is the new index: \")\n",
    "#print(ind_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "69aba44f-c0a6-4cc2-a00c-cf75364ea544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of labeled indexes \n",
    "# convert Index class to np.array and then to list of strings\n",
    "sampind_list = ind_sorted.values.tolist()\n",
    "#print(sampind_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7433bae3-9505-4e97-918d-121cdadd2d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all .filteredQualityReadCounts files\n",
    "# collect 'filtered' readcounts into array of dataframes \n",
    "readcounts_df = []\n",
    "for sample in ind_sorted: \n",
    "    # here we alter the code to read \".filteredQualityReadCounts\" files \n",
    "    df = pd.read_csv(\"./SpermAnalysis_Muller1/data/viz-Output/\" + sample + \"/\" + sample + \".filteredQualityReadCounts\", delimiter=\"\\t\", usecols=[0,2,3])\n",
    "    #print(df)\n",
    "    readcounts_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "65e02fe1-6dcd-49e7-b33f-5353cfa7ad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract event and count columns from each sample to create one big dataframe of all samples \n",
    "array_sampdf = []\n",
    "for ind,df in enumerate(readcounts_df): \n",
    "    sample_id = ind_sorted[ind]\n",
    "    sampdf = df[['event','count']]\n",
    "    sampdf = sampdf.set_index('event')\n",
    "    shortID = re.sub(r'-sperm', '_S', sample_id)\n",
    "    sampdf = sampdf.rename(columns={'count':f'{shortID}'})\n",
    "    array_sampdf.append(sampdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902dfd67-27a4-42b0-852f-5b4634f3ca62",
   "metadata": {},
   "source": [
    "### Write composite barcode matrix file \n",
    "###### You'll use this for generation of Muller plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "45226f85-3f09-4f89-ada5-3d6798409dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join dataframes together along the column axis, taking the union of indices \n",
    "newdf = pd.concat(array_sampdf, axis=1, sort=False)\n",
    "newdf.index.name = 'barcode'\n",
    "newdf.to_csv(experiments_subfolder+\"barcodeMatrix_3filters.tsv\", sep=\"\\t\") # save for ease of viewing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9a3120-6a47-46d0-802e-0cb71476b1fb",
   "metadata": {},
   "source": [
    "### Write barcode matrix file for each fish in data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f67dd5fe-afb6-4ad4-928e-437ecbb67395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect list of fish, each will get its own barcode matrix file\n",
    "# saved each fish name as a key in a dictionary with an empty list for the value\n",
    "fish_names = {}\n",
    "for fish in sampind_list: \n",
    "    fish = fish.split(\"_\")\n",
    "    fish_name = fish[0]\n",
    "    if fish_name not in fish_names: \n",
    "        fish_names[fish_name] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a0baa619-55b9-4f60-b9e4-268a17306349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all the keys in fish_names, populate its empty list with the matrices associated with that fish name\n",
    "for fish_name in fish_names.keys():\n",
    "    for sample in array_sampdf:\n",
    "        sample_name = str(sample).split(\"_\")[0].split(\" \")[-1]\n",
    "        if fish_name == sample_name: \n",
    "            fish_names[fish_name].append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aca5bb9e-1648-4619-8879-4f210a443f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fish each fish in the dictionary, write a barcode matrix file  \n",
    "for fish,matrix in fish_names.items(): \n",
    "    fish_df = pd.concat(matrix, axis = 1, sort = False)\n",
    "    fish_df.index.name = 'barcode'\n",
    "    fish_df.to_csv(experiments_subfolder + str(fish) + \"_barcodeMatrix_3filters.tsv\", sep=\"\\t\") # save for ease of viewing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3def7862-76e2-4073-8846-a74b30eccc58",
   "metadata": {},
   "source": [
    "### Step E summary report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8330eff8-59a6-4f32-8000-93eb8cf8e305",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = open(experiments_subfolder+\"stepE_summary.txt\", 'w')\n",
    "summary.write(\"Summary of step E: A barcode matrix file is written to the experiments folder and\\nis used for generating Muller plots.\\n\\n\")\n",
    "summary.write(\"A barcode matrix file is also written for each fish in your samples.\\n\")\n",
    "summary.write(\"The barcodes present in these matrix files will have passed all three filters (steps A, B and D)\")\n",
    "summary.write(\"\\n\")\n",
    "summary.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c4977a-1757-4508-885b-283177b19184",
   "metadata": {},
   "source": [
    "# Job report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2858f1cf-f9fe-44f4-8798-879bf2c8f568",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = open(experiments_subfolder+\"full_job_report.txt\", 'w')\n",
    "stepA = open(experiments_subfolder+\"stepA_summary.txt\", 'r')\n",
    "stepB = open(experiments_subfolder+\"stepB_summary.txt\", 'r')\n",
    "stepC = open(experiments_subfolder+\"stepC_summary.txt\", 'r')\n",
    "stepD = open(experiments_subfolder+\"stepD_summary.txt\", 'r')\n",
    "stepE = open(experiments_subfolder+\"stepE_summary.txt\", 'r')\n",
    "\n",
    "summary.write(\"Processed GESTALT barcodes from serially sampled sperm data.\\n\")\n",
    "summary.write(\"Your job completed at \" + datetime.datetime.now().strftime('%I:%M %p on %m/%d/%Y'))\n",
    "summary.write(\"\\nAndy Sposato wrote original code for steps A-D.\\nAndy adapted the code in Step E from original code written by Kimberly Truong.\")\n",
    "summary.write(\"\\n\\n############################################################################################\\n\\n\")\n",
    "for line in stepA.readlines(): \n",
    "    summary.write(line)\n",
    "stepA.close()\n",
    "summary.write(\"\\n############################################################################################\\n\\n\")\n",
    "for line in stepB.readlines(): \n",
    "    summary.write(line)\n",
    "stepB.close()\n",
    "summary.write(\"############################################################################################\\n\\n\")\n",
    "for line in stepC.readlines(): \n",
    "    summary.write(line)\n",
    "stepC.close()\n",
    "summary.write(\"############################################################################################\\n\\n\")\n",
    "for line in stepD.readlines(): \n",
    "    summary.write(line)\n",
    "stepD.close()\n",
    "summary.write(\"############################################################################################\\n\\n\")\n",
    "for line in stepE.readlines(): \n",
    "    summary.write(line)\n",
    "stepE.close()\n",
    "summary.write(\"\\n############################################################################################\\n\\n\")\n",
    "summary.write(\"It was a pleasure filtering your sperm barcodes. \\n\")\n",
    "summary.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
